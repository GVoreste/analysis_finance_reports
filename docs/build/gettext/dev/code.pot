# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, Oreste Sciacqualegni
# This file is distributed under the same license as the freeports_analysis package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: freeports_analysis \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-07-14 11:57+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../source/dev/code.rst:3
msgid "Code development"
msgstr ""

#: ../../source/dev/code.rst:5
msgid "The focus of this guide is the development of the code related specific to the parsing of a `pdf format`. With `pdf format` we identify the series of operations and the code necessary to parse to `csv` a series of financial reports."
msgstr ""

#: ../../source/dev/code.rst:9
msgid "We decided to implement a structure flexible enough to be able to parse different reports, but making some hypotesys in order to semplify and standardize the parsing process. The aim is to make to not repeat all the code common to all the format so that the contributions can focus on enlarge the database of the supported pdf."
msgstr ""

#: ../../source/dev/code.rst:13
msgid "The general schema for parsing a pdf can be rappresented with the following:"
msgstr ""

#: ../../source/dev/code.rst:17
msgid "The document is firstly divided in different pages and converted in a ``xml`` string using the `PyMuPDF <https://pypi.org/project/PyMuPDF/>`_ package. The assumption is that each page of the document contain the necessary information to get the context and to understand the meaning of the data relevant to construct the final `csv file`. This assumption seems quite resrtictive, but it is very essential in order to simplify and design reasonably fast pasrsing algorithms. This assumption makes possible to implement data level parallelism on the pdf pages; now the current implementation run on different batch of pages in parallel spawning different processes (when in :ref:`BATCH MODE <batch_mode>` the parallelism is done at document level and the different pages are processed sequentially). The idea behind the assumption is that a well designed pdf page should contain all the necessary information for a human being to understand the context. If this assumption will show to be too resrtictive we could not assume that the context of the page would be the previous pages, but we would be forced to parse the document subsequent times in order to get the relevant context."
msgstr ""

#: ../../source/dev/code.rst:27
msgid "Sometimes the information doesn't seems to be self contained but this dependence is only a one to one, one to many or many to many relation between the different objects. An example of this can be the case of the parsing of a pdf document containing some data related to some customers and in other pages, about orders and products. In this example it seems that the `Customer`, the `Product` and the `Order` records are interdependent, but depending of the report design the algorithm can parse the self contained information of `Customers`, `Products` and `Orders` and just right before the csv output relate the different record with an ``id`` field (for uderstanding better the proposed approach for how to treat these kind of cases think at the concept of `foreign key <https://en.wikipedia.org/wiki/Foreign_key>`_ in the database realm). The assumption breaks in the presence of a true dependence of the information."
msgstr ""

#: ../../source/dev/code.rst:34
msgid "The developer that wants to add a series of reports to the supported ones, has to provide the specific implementation of the ``PdfFilter``, ``TextExtract`` and ``Deserialize`` functions (with them of the ``PdfBlock`` and ``TextBlock`` classes). Each ``xml`` page will be parsed by a ``PdfFilter`` function that will output a list of relevant ``PdfBlocks``. The content of these blocks is related and parsed by a function called ``TextExtract`` and output a list of blocks that have a one to one relation with the information that will populate a csv row called ``TextBlock``. Each block is parsed independently into an object (an abstract ``FinancialData``) that as to be one between the one reconnaissed by the system (for now ``Equity`` and ``Bond``). The financial data is then serialized in a python dict in a predefined way and output to a the resulting csv file."
msgstr ""

#: ../../source/dev/code.rst:43
msgid "``PdfFilter``"
msgstr ""

#: ../../source/dev/code.rst:45
msgid "The aim of this function is to filter from the ``xml`` rappresentation of the pdf page the relevant information using the layout or the typografic signature of them. A constraint that we choose to try to respect is to use only information related to the grafical appearance of the pdf without looking at the textual content and parse it semantically or evaluating the meaning. This constraint is important to divide the complexity of parsing a pdf in more straight forward and standardized steps. The typical ``PdfFilter`` function will look at the font, the position of the different parts of the pdf and eventually part of the text that is fixed and is considered part of the page layout (for example a header present in all pages), from this will compute some bit of information and add converge to some ``PdfBlocks`` with their custom metadata."
msgstr ""

#: ../../source/dev/code.rst:54
msgid "``TextExtract``"
msgstr ""

#: ../../source/dev/code.rst:56
msgid "The aim of this function is to extract from the ``PdfBlocks``  the relevant blocks of text and add semantic information. In particular this function is the one that takes in input the list of the target companies and that look at the content of the variable text present in the ``PdfBlocks``. The typical ``TextExtract`` function will use `regular expressions <https://en.wikipedia.org/wiki/Regular_expression>`_ to understand the role of each part of test and to extract the relevant information of the financial data related with the companies of interest."
msgstr ""

#: ../../source/dev/code.rst:63
msgid "``Deserialize``"
msgstr ""

#: ../../source/dev/code.rst:65
msgid "The aim of this function is to transform the accumulated information into a python object with some standard fields and validate them. This function will cast the data into the python types that more reflect the nature of the accumulated data. In this steps no filtering is done, each ``TextBlock`` will correspond to a python object. This constraint impose the focus of this function to the cast operation of the different field. The abstract class that this function output is called ``FinancialData``. Each class field is read only and consists in some core information and some additional infos. The concrete classes that inherit from ``FinancialData`` for now are the ``Equity`` and ``Bond`` classes (the bond class has the interest rate and the maturity date as additional infos). This objects are then casted in a predefined way in a python dict and then with `Pandas <https://en.wikipedia.org/wiki/Pandas_(software)>`_ on a dataframe dumped directly in a `csv file`."
msgstr ""

#: ../../source/dev/code.rst:75
msgid "``PdfBlock`` and ``TextBlock``"
msgstr ""

#: ../../source/dev/code.rst:77
msgid "These block consists of three part:"
msgstr ""

#: ../../source/dev/code.rst:79
msgid "A ``BlockType`` (``PdfBlockType`` and ``TextBlockType``), that is a required label that identify the grafical and the semantic role of the information bit. These two fieds are implemented as enums and the possible values has to be chosen by the format developer (it is part of the format specification)"
msgstr ""

#: ../../source/dev/code.rst:81
msgid "A ``metadata`` field, that should contain custom data related to graphical and semantic information. The ``BlockType`` should be related to the expected keys in the metadata field. The implementation is a free and optional python dict"
msgstr ""

#: ../../source/dev/code.rst:83
msgid "An optional ``content`` field, that should contain the textual information in the pdf related to the block"
msgstr ""

#: ../../source/dev/code.rst:85
msgid "in addition to these fields, the ``TextBlock`` has a ``PdfBlock`` related to him from which is is taken from (if it is computed from more, the most important)."
msgstr ""

#: ../../source/dev/code.rst:91
msgid "In practice"
msgstr ""

#: ../../source/dev/code.rst:93
msgid "If you want to create the support for a new format you should choose a name and create a directory with same name into ``src/freeports_analysis/formats``. In this directory you can put the number of files and subdirectory that you want, the only constraint is that when imported as a submodule, the package expect to find the three function ``PdfFilter``, ``TextExtract``, ``Deserialize`` with their respective signatures and the definition of the two enums ``PdfBlockType`` and ``TextBlockType``. You can take as reference the format called ``_default`` as a template. For helping the support for new formats we provide a series of utilities into the submodule ``src/freeports_analysis/formats_utils``. These utilities divide in four different kind of helpers:"
msgstr ""

#: ../../source/dev/code.rst:99
msgid "useful function to create the parsing algorithm"
msgstr ""

#: ../../source/dev/code.rst:100
msgid "decorators for adding standard functionalities to the parsing functions"
msgstr ""

#: ../../source/dev/code.rst:101
msgid "decorators that provide a standard implementation of ``PdfFilter``, ``TextExtract`` and ``Deserialize``"
msgstr ""

#: ../../source/dev/code.rst:102
msgid "enums containing common ``PdfBlockType`` and ``TextBlockType`` implementations"
msgstr ""

#: ../../source/dev/code.rst:104
msgid "the aim is to see the repeatitive parsing patterns and create some routines and implementation that can be parametrized and reused. To activate the support for a certain format, his name in capslock has to be added to the ``src/freeports_analysis/data/format_url_mapping.yaml`` file; this file is composed with some format names (this name lowered will be the same of the module loaded to parse the pdf) and a list of regular expressions used against url provided (``URL``) as a program argument to infer the correct format to use upon remote resource parsing."
msgstr ""

#: ../../source/dev/code.rst:110
msgid "the order of the regular expressions and of the formats matters, because the inferred one is the first match of this list."
msgstr ""

#: ../../source/dev/code.rst:112
msgid "Last but not least there is a directory in the repository called ``devtools/`` whit a template `Jupyter Notebook <https://jupyter.org/>`_ and some utilities for examining the pdf, developing the format specification and tests. This directory is intended as the directory where to design and experiment with the different component before integrating in the package. In order to use the notebook, copy the template and rename it as you want (deleting the ``.template.`` part)."
msgstr ""
